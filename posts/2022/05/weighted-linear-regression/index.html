<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Weighted Linear Regression - Andrea Conti PhD</title><meta name="Description" content=""><meta property="og:title" content="Weighted Linear Regression" />
<meta property="og:description" content="Weighted Linear Regression Linear Regression If you are here there are high chances you already know how a simple linear regression works, it is the first and simplest algorithm you meet you your machine learning journey, but let&rsquo;s recap since it will be useful to later introduce its weighted form.
Let&rsquo;s say that you have a set of values $X$ and for each of them a target value $Y$, if you plot them can be easily seen that they could be approximated by a simple straight line:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://andreaconti.github.io/posts/2022/05/weighted-linear-regression/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-09T16:18:28+02:00" />
<meta property="article:modified_time" content="2022-05-09T16:18:28+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Weighted Linear Regression"/>
<meta name="twitter:description" content="Weighted Linear Regression Linear Regression If you are here there are high chances you already know how a simple linear regression works, it is the first and simplest algorithm you meet you your machine learning journey, but let&rsquo;s recap since it will be useful to later introduce its weighted form.
Let&rsquo;s say that you have a set of values $X$ and for each of them a target value $Y$, if you plot them can be easily seen that they could be approximated by a simple straight line:"/>
<meta name="application-name" content="Andrea Conti PhD">
<meta name="apple-mobile-web-app-title" content="Andrea Conti PhD"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://andreaconti.github.io/posts/2022/05/weighted-linear-regression/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Weighted Linear Regression",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/andreaconti.github.io\/posts\/2022\/05\/weighted-linear-regression\/"
        },"genre": "posts","wordcount":  781 ,
        "url": "https:\/\/andreaconti.github.io\/posts\/2022\/05\/weighted-linear-regression\/","datePublished": "2022-05-09T16:18:28+02:00","dateModified": "2022-05-09T16:18:28+02:00","publisher": {
            "@type": "Organization",
            "name": "Andrea Conti"},"author": {
                "@type": "Person",
                "name": "Andrea Conti"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('light' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'light' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Andrea Conti PhD">Andrea Conti</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/projects/"> Projects </a><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/about"> About </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Andrea Conti PhD">Andrea Conti</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/projects/" title="">Projects</a><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/about" title="">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Weighted Linear Regression</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Andrea Conti</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-05-09">2022-05-09</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;781 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;4 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#linear-regression">Linear Regression</a></li>
    <li><a href="#linear-regression-properties">Linear Regression Properties</a>
      <ul>
        <li><a href="#linearity">Linearity</a></li>
        <li><a href="#normality">Normality</a></li>
        <li><a href="#independency">Independency</a></li>
        <li><a href="#low-multi-collinearity">Low Multi-Collinearity</a></li>
        <li><a href="#homoscedasticity">Homoscedasticity</a></li>
      </ul>
    </li>
    <li><a href="#weighted-linear-regression-1">Weighted Linear Regression</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h1 id="weighted-linear-regression">Weighted Linear Regression</h1>
<h2 id="linear-regression">Linear Regression</h2>
<p>If you are here there are high chances you already know how a simple linear regression works, it is the first and simplest algorithm you meet you your machine learning journey, but let&rsquo;s recap since it will be useful to later introduce its <em>weighted</em> form.</p>
<p>Let&rsquo;s say that you have a set of values $X$ and for each of them a <em>target</em> value $Y$, if you plot them can be easily seen that they could be approximated by a simple straight line:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&#34;b.&#34;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;X&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;Y&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="index_files/index_3_0.png"
        data-srcset="/posts/2022/05/weighted-linear-regression/index_files/index_3_0.png, index_files/index_3_0.png 1.5x, /posts/2022/05/weighted-linear-regression/index_files/index_3_0.png 2x"
        data-sizes="auto"
        alt="/posts/2022/05/weighted-linear-regression/index_files/index_3_0.png"
        title="png" /></p>
<p>Your goal is to find the best straight line which better approximates the data behaviour, this means that you want to find $\alpha$ and $\beta$ such that:</p>
<p>$$\operatorname{argmin}_{\alpha, \beta} \sum_i (y_i - (\alpha + \beta x_i)^2$$</p>
<p>Once you have them you can predict the output for every $X$ with:</p>
<p>$$y_{pred} = \alpha + \beta x$$</p>
<p>The really interesing thing about linear regression is that the best fit can be optained in <em>closed form</em>, i.e. solving a simple formula:</p>
<p>$$\beta = \frac{\sum_i(x_i - \hat x)(y_i - \hat y)}{\sum_i(x_i - \hat x)}$$
$$\alpha = \hat y - \beta \hat x$$</p>
<p>Where $\hat x$ and $\hat y$ are respectively the mean of all the $X$ and $Y$ values. It could be expressed also by means of matrix multiplications but here we&rsquo;ll stick with this form since it can be easily implemented through broadcasting in numpy.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">linear_regression</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">xm</span><span class="p">,</span> <span class="n">ym</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">xm</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">ym</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">xm</span><span class="p">))</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">ym</span> <span class="o">-</span> <span class="n">b</span> <span class="o">*</span> <span class="n">xm</span>
    <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span>

<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">linear_regression</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&#34;b.&#34;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&#34;r--&#34;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="index_files/index_5_0.png"
        data-srcset="/posts/2022/05/weighted-linear-regression/index_files/index_5_0.png, index_files/index_5_0.png 1.5x, /posts/2022/05/weighted-linear-regression/index_files/index_5_0.png 2x"
        data-sizes="auto"
        alt="/posts/2022/05/weighted-linear-regression/index_files/index_5_0.png"
        title="png" /></p>
<h2 id="linear-regression-properties">Linear Regression Properties</h2>
<p>Now, it&rsquo;s important to observe that linear regression makes some assumptions over the data used, if these assumptions do not hold the closed form will lead to suboptimal results.</p>
<h3 id="linearity">Linearity</h3>
<p>The dependent variable ($Y$) has a linear relationship with the independent one ($X$), this is pretty obvious, for instance the following function can only poorly represented through a linear regression:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;X&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;Y&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="s2">&#34;b-&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="index_files/index_8_0.png"
        data-srcset="/posts/2022/05/weighted-linear-regression/index_files/index_8_0.png, index_files/index_8_0.png 1.5x, /posts/2022/05/weighted-linear-regression/index_files/index_8_0.png 2x"
        data-sizes="auto"
        alt="/posts/2022/05/weighted-linear-regression/index_files/index_8_0.png"
        title="png" /></p>
<h3 id="normality">Normality</h3>
<p>The observation errors are normally distributed</p>
<h3 id="independency">Independency</h3>
<p>The error of each observation is independent to the others, this means that the error that you can see in a observation can not affect the error of other observations</p>
<h3 id="low-multi-collinearity">Low Multi-Collinearity</h3>
<p>There isn&rsquo;t high correlation among the independent variables</p>
<h3 id="homoscedasticity">Homoscedasticity</h3>
<p>All the observation errors have the same finite variance, basically this means that you assume that the noise present in you observations varies always inside the same range following a gaussian distribution which has the same variance. When this assumption does not hold you are dealing with a case of <em>Heteroscedasticity</em>. Following an example of Homoscedasticity in which the linear regression fails due to the high quantity of <em>outliers</em>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">y_hetero</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">linear_regression</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_hetero</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;X&#34;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;Y&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_hetero</span><span class="p">,</span> <span class="s2">&#34;bo&#34;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="s2">&#34;r--&#34;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">3.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="index_files/index_10_0.png"
        data-srcset="/posts/2022/05/weighted-linear-regression/index_files/index_10_0.png, index_files/index_10_0.png 1.5x, /posts/2022/05/weighted-linear-regression/index_files/index_10_0.png 2x"
        data-sizes="auto"
        alt="/posts/2022/05/weighted-linear-regression/index_files/index_10_0.png"
        title="png" /></p>
<h2 id="weighted-linear-regression-1">Weighted Linear Regression</h2>
<p>We are particularly interested in the Homoscedasticity property since relaxing this linear regression property leads to the capability to handle outliers. We can model each observation to be a random normal variable with its own variance and we want to <em>weight</em> each observation by means of its variance. The problem to be solved becomes thus:</p>
<p>$$\operatorname{argmin}_{\alpha, \beta} \sum_i \frac{1}{\sigma_i}(y_i - (\alpha + \beta x_i)^2$$</p>
<p>The closed form to find $\alpha$ and $\beta$ in the weighted case is:</p>
<p>$$\beta = \frac{\sum_i w_i(x_i - \hat x)(y_i - \hat y)}{\sum_i w_i (x_i - \hat x)^2}$$
$$\alpha = \hat y - \beta \hat x$$
$$\hat x = \frac{\sum_i w_ix_i}{\sum_i w_i}$$
$$\hat y = \frac{\sum_i w_iy_i}{\sum_i w_i}$$</p>
<p>Below an example where a portion of data is not representative and it is ignored assigning them zero weight.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">weighted_linear_regression</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">xm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="n">ym</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">xm</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">ym</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">xm</span><span class="p">))</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">ym</span> <span class="o">-</span> <span class="n">b</span> <span class="o">*</span> <span class="n">xm</span>
    <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span>

<span class="n">y_outliers</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_outliers</span><span class="p">[</span><span class="o">-</span><span class="mi">200</span><span class="p">:]</span> <span class="o">=</span> <span class="n">y_outliers</span><span class="p">[</span><span class="o">-</span><span class="mi">200</span><span class="p">:]</span> <span class="o">+</span> <span class="mi">80</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_outliers</span><span class="p">,</span> <span class="s2">&#34;b.&#34;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]:</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y_outliers</span><span class="p">)</span>
    <span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">200</span><span class="p">:]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">weighted_linear_regression</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_outliers</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;weight: </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="index_files/index_12_0.png"
        data-srcset="/posts/2022/05/weighted-linear-regression/index_files/index_12_0.png, index_files/index_12_0.png 1.5x, /posts/2022/05/weighted-linear-regression/index_files/index_12_0.png 2x"
        data-sizes="auto"
        alt="/posts/2022/05/weighted-linear-regression/index_files/index_12_0.png"
        title="png" /></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2022-05-09</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Andrea Conti</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><script type="text/javascript" src="https://%3cnil%3e.disqus.com/embed.js" defer></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":null,"maxResultLength":null,"noResultsFound":"No results found","snippetLength":null}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
