<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Unsupervised Confidence for LiDAR Depth Maps and Applications - Andrea Conti PhD</title><meta name="Description" content="Depth perception is pivotal in many fields, such as robotics and autonomous driving, to name a few. Conse- quently, depth sensors such as LiDARs rapidly spread in many applications. The 3D point clouds generated by these sensors must often be coupled with an RGB camera to understand the framed scene semantically. Usually, the former is projected over the camera image plane, leading to a sparse depth map. Unfortunately, this process, coupled with the intrinsic issues affecting all the depth sensors, yields noise and gross outliers in the final output. Purposely, in this paper, we propose an effective unsupervised framework aimed at explicitly addressing this issue by learning to estimate the confidence of the LiDAR sparse depth map and thus allowing for filtering out the outliers. Experimental results on the KITTI dataset highlight that our framework excels for this purpose. Moreover, we demonstrate how this achievement can improve a wide range of tasks."><meta property="og:title" content="Unsupervised Confidence for LiDAR Depth Maps and Applications" />
<meta property="og:description" content="Depth perception is pivotal in many fields, such as robotics and autonomous driving, to name a few. Conse- quently, depth sensors such as LiDARs rapidly spread in many applications. The 3D point clouds generated by these sensors must often be coupled with an RGB camera to understand the framed scene semantically. Usually, the former is projected over the camera image plane, leading to a sparse depth map. Unfortunately, this process, coupled with the intrinsic issues affecting all the depth sensors, yields noise and gross outliers in the final output. Purposely, in this paper, we propose an effective unsupervised framework aimed at explicitly addressing this issue by learning to estimate the confidence of the LiDAR sparse depth map and thus allowing for filtering out the outliers. Experimental results on the KITTI dataset highlight that our framework excels for this purpose. Moreover, we demonstrate how this achievement can improve a wide range of tasks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://andreaconti.github.io/projects/unsupervised_confidence_for_lidar_depth_maps_and_applications/" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2022-10-12T17:32:00+02:00" />
<meta property="article:modified_time" content="2022-10-12T17:32:00+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Unsupervised Confidence for LiDAR Depth Maps and Applications"/>
<meta name="twitter:description" content="Depth perception is pivotal in many fields, such as robotics and autonomous driving, to name a few. Conse- quently, depth sensors such as LiDARs rapidly spread in many applications. The 3D point clouds generated by these sensors must often be coupled with an RGB camera to understand the framed scene semantically. Usually, the former is projected over the camera image plane, leading to a sparse depth map. Unfortunately, this process, coupled with the intrinsic issues affecting all the depth sensors, yields noise and gross outliers in the final output. Purposely, in this paper, we propose an effective unsupervised framework aimed at explicitly addressing this issue by learning to estimate the confidence of the LiDAR sparse depth map and thus allowing for filtering out the outliers. Experimental results on the KITTI dataset highlight that our framework excels for this purpose. Moreover, we demonstrate how this achievement can improve a wide range of tasks."/>
<meta name="application-name" content="Andrea Conti PhD">
<meta name="apple-mobile-web-app-title" content="Andrea Conti PhD"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://andreaconti.github.io/projects/unsupervised_confidence_for_lidar_depth_maps_and_applications/" /><link rel="next" href="https://andreaconti.github.io/projects/sparsity_agnostic_depth_completion/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Unsupervised Confidence for LiDAR Depth Maps and Applications",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/andreaconti.github.io\/projects\/unsupervised_confidence_for_lidar_depth_maps_and_applications\/"
        },"genre": "projects","keywords": "confidence, deep-learning, computer-vision, iros","wordcount":  601 ,
        "url": "https:\/\/andreaconti.github.io\/projects\/unsupervised_confidence_for_lidar_depth_maps_and_applications\/","datePublished": "2022-10-12T17:32:00+02:00","dateModified": "2022-10-12T17:32:00+02:00","publisher": {
            "@type": "Organization",
            "name": "Andrea Conti"},"author": {
                "@type": "Person",
                "name": "Andrea Conti"
            },"description": "Depth perception is pivotal in many fields, such as robotics and autonomous driving, to name a few. Conse- quently, depth sensors such as LiDARs rapidly spread in many applications. The 3D point clouds generated by these sensors must often be coupled with an RGB camera to understand the framed scene semantically. Usually, the former is projected over the camera image plane, leading to a sparse depth map. Unfortunately, this process, coupled with the intrinsic issues affecting all the depth sensors, yields noise and gross outliers in the final output. Purposely, in this paper, we propose an effective unsupervised framework aimed at explicitly addressing this issue by learning to estimate the confidence of the LiDAR sparse depth map and thus allowing for filtering out the outliers. Experimental results on the KITTI dataset highlight that our framework excels for this purpose. Moreover, we demonstrate how this achievement can improve a wide range of tasks."
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('light' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'light' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Andrea Conti PhD">Andrea Conti</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/projects/"> Projects </a><a class="menu-item" href="/about"> About </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Andrea Conti PhD">Andrea Conti</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/projects/" title="">Projects</a><a class="menu-item" href="/about" title="">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX" style="text-align: center; font-size: 200%;">Unsupervised Confidence for LiDAR Depth Maps and Applications</h1><div style="display: none;" class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Andrea Conti</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-10-12">2022-10-12</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;601 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;3 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#qualitative-results">Qualitative Results</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><!-- raw HTML omitted -->


<p style="text-align: center;">
    <a href="https://andreaconti.github.io" target="_blank">Andrea Conti</a>
    &middot
    <a href="https://mattpoggi.github.io" target="_blank">Matteo Poggi</a>
    &middot 
    <a href="https://filippoaleotti.github.io/website" target="_blank">Filippo Aleotti</a>
    &middot
    <a href="http://www.vision.deis.unibo.it/~smatt/Site/Home.html" target="_blank">Stefano Mattoccia</a>
</p>
<div style="text-align: center;">
    <a target="blank" href="https://github.com/andreaconti/lidar-confidence">[code]</a>
    <a target="blank" href="https://github.com/andreaconti/lidar-confidence/blob/master/torchhub-example.ipynb">[demo]</a>
    <a target="blank" href="https://arxiv.org/pdf/2210.03118.pdf">[paper]</a>
</div>




<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/image.png"
         alt="(a)" width="600px"/><figcaption>
            <p>(a)</p>
        </figcaption>
</figure>

<figure><img src="images/lidar_3d.png"
         alt="(b)" width="770px"/><figcaption>
            <p>(b)</p>
        </figcaption>
</figure>

<figure><img src="images/lidar.png"
         alt="(c)" width="600px"/><figcaption>
            <p>(c)</p>
        </figcaption>
</figure>

<figure><img src="images/lidar_filtered.png"
         alt="(d)" width="600px"/><figcaption>
            <p>(d)</p>
        </figcaption>
</figure>

</div>
    
        <div class="caption"><b>Unsupervised Confidence for LiDAR Depth Maps and Applications.</b> Given an image (a) and a LiDAR point cloud (b) the projection of the latter over the image plane does not properly handle occlusions between the two points of view, assigning wrong depth values to the foreground (c). Our method (d) learns to remove these outliers reliably and without supervision.</div>
    
</div>
<h2 id="overview">Overview</h2>
<p>Depth perception is pivotal in many fields, such as robotics and autonomous driving, to name a few. Consequently, depth sensors such as LiDARs rapidly spread in many applications. The 3D point clouds generated by these sensors must often be coupled with an RGB camera to understand the framed scene semantically. Usually, the former is projected over the camera image plane, leading to a sparse depth map. Unfortunately, this process, coupled with the intrinsic issues affecting all the depth sensors, yields noise and gross outliers in the final output. As an example, in the image below the outliers formation process due to visual occlusions between camera and depth sensor is showed.</p>



<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/lidar_occlusion.jpg" width="600px"/>
</figure>

</div>
    
        <div class="caption"><b>Outliers formation process due to occlusion.</b> When a LiDAR and an RGB camera acquire from different viewpoints, projecting the point cloud into a depth map (a) on the image (b) introduces outliers (blue oval), e.g. points visible by the  LiDAR occluced to the camera (red), yet projected near foreground points visible to both (green).</div>
    
</div>
<p>We propose an effective unsupervised framework aimed at explicitly addressing this issue by learning to estimate the confidence of the LiDAR sparse depth map and thus allowing for filtering out the outliers.</p>



<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/framework.jpg" width="600px"/>
</figure>

</div>
    
        <div class="caption"><b>Proposed Architecture.</b> A convolutional encoder (orange) extracts features at different resolutions. We query features fro each pixel with a valid LiDAR value and concatenate them (&#43;) in a vector, fed to an MLP (blue) to estimate confidence only in the LiDAR valid coordinates.</div>
    
</div>
<p>To train our framework we model the confidence of LiDAR depth $d$ assuming a Gaussian Distribution and minimize the negative log-likelihood function.</p>
<p>$$
\mathcal{L}_G = - \ln \left( \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(d - d^*)^2}{2\sigma^2}} \right)
$$</p>
<p>which can be rewritten as follows</p>
<p>$$
\mathcal{L}_G \approx \ln(\sigma) + \frac{(d - d^*)^2}{2\sigma^2}
$$</p>
<p>To apply the loss function above the  preduction of both $d^<em>, \sigma$ is required. However, doing so means learn the confidence $\sigma$ of the network output $d^</em>$ and this is not our goal. Thus, instead of predict $d^*$ we employ a <em>proxy label</em> computed as follows representing a plausibly correct depth for each original LiDAR depth value.</p>
<p>$$
d^*_x  = \min \ \{ d : d \in P(x), d &gt; 0 \}
$$</p>
<p>Where $x$ is a valid coordinate and $P(x)$ a patch of size $N \times N$. Using the minimum depth value correctly select the foreground points as reliable in presence of occlusions.
As a drawback, it may lead to indiscriminately detecting as outliers most of the pixels in the background, even if not occluded. However, in practice, we will show that the network network is not extremelly affected by this approssimation that is on the other hand fast and unsupervised. Further details are described in our <a href="https://arxiv.org/pdf/2210.03118.pdf" target="_blank" rel="noopener noreffer">paper</a>.</p>
<h2 id="qualitative-results">Qualitative Results</h2>
<p>In this section we report a small set of examples, for each one we show respectively the image, the raw lidar, the lidar filtered with our approach and our sparse confidence map.</p>
<p>


<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/qualitatives/sample1/rgb.png" width="600px"/>
</figure>

<figure><img src="images/qualitatives/sample1/lidar.png" width="600px"/>
</figure>

</div>
    
</div>



<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/qualitatives/sample1/lidar_ours.png" width="600px"/>
</figure>

<figure><img src="images/qualitatives/sample1/confidence_ours.png" width="600px"/>
</figure>

</div>
    
        <div class="caption"><b>KITTI Drive 05 26/09/2011.</b> </div>
    
</div></p>
<p>


<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/qualitatives/sample2/rgb.png" width="600px"/>
</figure>

<figure><img src="images/qualitatives/sample2/lidar.png" width="600px"/>
</figure>

</div>
    
</div>



<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/qualitatives/sample2/lidar_ours.png" width="600px"/>
</figure>

<figure><img src="images/qualitatives/sample2/confidence_ours.png" width="600px"/>
</figure>

</div>
    
        <div class="caption"><b>KITTI Drive 22 26/09/2011.</b> </div>
    
</div></p>
<p>


<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/qualitatives/sample3/rgb.png" width="600px"/>
</figure>

<figure><img src="images/qualitatives/sample3/lidar.png" width="600px"/>
</figure>

</div>
    
</div>



<style>
    .imggridbox {
       margin: 0px 0px;
       text-align: center;
       font-weight: lighter;
       font-size: smaller;
    }

    .imggrid {
        margin: 0px 0px;
        display: flex;
        justify-content: center;
    }

    .caption {
        text-align: justify;
        font-weight: bolder;
        margin: 0px auto;
    }
</style>

<div class="imggridbox">
    <div class="imggrid">
<figure><img src="images/qualitatives/sample3/lidar_ours.png" width="600px"/>
</figure>

<figure><img src="images/qualitatives/sample3/confidence_ours.png" width="600px"/>
</figure>

</div>
    
        <div class="caption"><b>KITTI Drive 71 29/09/2011.</b> </div>
    
</div></p>
<h2 id="reference">Reference</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bibtex" data-lang="bibtex"><span class="line"><span class="cl"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">aconti2022lidarconf</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">title</span><span class="p">=</span><span class="s">{Unsupervised confidence for LiDAR depth maps and applications}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">author</span><span class="p">=</span><span class="s">{Conti, Andrea and Poggi, Matteo and Aleotti, Filippo and Mattoccia, Stefano}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">booktitle</span><span class="p">=</span><span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">note</span><span class="p">=</span><span class="s">{IROS}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">year</span><span class="p">=</span><span class="s">{2022}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2022-10-12</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/confidence/">confidence</a>,&nbsp;<a href="/tags/deep-learning/">deep-learning</a>,&nbsp;<a href="/tags/computer-vision/">computer-vision</a>,&nbsp;<a href="/tags/iros/">iros</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav">
            <a href="/projects/sparsity_agnostic_depth_completion/" class="next" rel="next" title="Sparsity Agnostic Depth Completion">Sparsity Agnostic Depth Completion<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Andrea Conti</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><script type="text/javascript" src="https://%3cnil%3e.disqus.com/embed.js" defer></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":null,"maxResultLength":null,"noResultsFound":"No results found","snippetLength":null}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
