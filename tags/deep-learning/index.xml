<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>deep-learning - Tag - Andrea Conti PhD</title>
        <link>https://andreaconti.github.io/tags/deep-learning/</link>
        <description>deep-learning - Tag - Andrea Conti PhD</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>andrea.conti@tutanota.com (Andrea Conti)</managingEditor>
            <webMaster>andrea.conti@tutanota.com (Andrea Conti)</webMaster><lastBuildDate>Tue, 28 Nov 2023 17:32:00 &#43;0200</lastBuildDate><atom:link href="https://andreaconti.github.io/tags/deep-learning/" rel="self" type="application/rss+xml" /><item>
    <title>Range-Agnostic Multi-View Depth Estimation With Keyframe Selection</title>
    <link>https://andreaconti.github.io/projects/range_agnostic_multi_view_depth/</link>
    <pubDate>Tue, 28 Nov 2023 17:32:00 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://andreaconti.github.io/projects/range_agnostic_multi_view_depth/</guid>
    <description><![CDATA[Andrea Conti &middot Matteo Poggi &middot Valerio Cambareri &middot Stefano Mattoccia [Paper] [Code] [Demo] Overview Multi-View 3D reconstruction techniques process a set of source views and a reference view to yield an estimated depth map for the latter. Unluckily, state-of-the-art frameworks
require to know a priori the depth range of the scene, in order to sample a set of depth hypotheses and build a meaningful cost volume. do not take into account the keyframes selection.]]></description>
</item><item>
    <title>Active Stereo Without Pattern Projector</title>
    <link>https://andreaconti.github.io/projects/active_stereo_without_pattern_projector/</link>
    <pubDate>Wed, 27 Sep 2023 11:44:00 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://andreaconti.github.io/projects/active_stereo_without_pattern_projector/</guid>
    <description><![CDATA[This paper proposes a novel framework integrating the principles of active stereo in standard passive cameras, yet in the absence of a physical pattern projector. Our methodology virtually projects a pattern over left and right images, according to sparse measurements obtained from a depth sensor. Any of such devices can be seamlessly plugged into our framework, allowing for the deployment of a virtual active stereo setup in any possible environments overcoming the limitation of physical patterns, such as limited working range. Exhaustive experiments on indoor/outdoor datasets, featuring both long and close-range, support the seamless effectiveness of our approach, boosting the accuracy of both stereo algorithms and deep networks.]]></description>
</item><item>
    <title>Boosting Multi-Modal Unsupervised Domain Adaptation for LiDAR Semantic Segmentation by Self-Supervised Depth Completion</title>
    <link>https://andreaconti.github.io/projects/boosting_uda_lidar_segmentation/</link>
    <pubDate>Fri, 25 Aug 2023 11:44:00 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://andreaconti.github.io/projects/boosting_uda_lidar_segmentation/</guid>
    <description><![CDATA[LiDAR semantic segmentation is receiving increased attention due to its deployment in autonomous driving applications. As LiDARs come often with other sensors such as RGB cameras, multi-modal approaches for this task have been developed, which however suffer from the domain shift problem as other deep learning approaches. To address this, we propose a novel Unsupervised Domain Adaptation (UDA) technique for multi-modal LiDAR segmentation. Unlike previous works in this field, we leverage depth completion as an auxiliary task to align features extracted from 2D images across domains, and as a powerful data augmentation for LiDARs. We validate our method on three popular multi-modal UDA benchmarks and we achieve better performances than other competitors.]]></description>
</item><item>
    <title>Sparsity Agnostic Depth Completion</title>
    <link>https://andreaconti.github.io/projects/sparsity_agnostic_depth_completion/</link>
    <pubDate>Tue, 03 Jan 2023 17:32:00 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://andreaconti.github.io/projects/sparsity_agnostic_depth_completion/</guid>
    <description><![CDATA[Andrea Conti &middot Matteo Poggi &middot Stefano Mattoccia [Paper] [Code] Overview State-of-the-art Depth Completion approaches yield accurate results only when processing a specific density and distribution of input points, i.e. the one observed during training, narrowing their deployment in real use cases. We present a framework:
robust to uneven distributions and extremely low densities by structure trained with a fixed pattern and density as competitors, without any need of augmenting Experimental results on standard indoor and outdoor benchmarks highlight the robustness of our framework, achieving accuracy comparable to state-of-the-art methods when tested with density and distribution equal to the training one while being much more accurate in the other cases.]]></description>
</item><item>
    <title>Unsupervised Confidence for LiDAR Depth Maps and Applications</title>
    <link>https://andreaconti.github.io/projects/unsupervised_confidence_for_lidar_depth_maps_and_applications/</link>
    <pubDate>Wed, 12 Oct 2022 17:32:00 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://andreaconti.github.io/projects/unsupervised_confidence_for_lidar_depth_maps_and_applications/</guid>
    <description><![CDATA[Andrea Conti &middot Matteo Poggi &middot Filippo Aleotti &middot Stefano Mattoccia [code] [demo] [paper] (a)
(b)
(c)
(d)
Unsupervised Confidence for LiDAR Depth Maps and Applications. Given an image (a) and a LiDAR point cloud (b) the projection of the latter over the image plane does not properly handle occlusions between the two points of view, assigning wrong depth values to the foreground (c). Our method (d) learns to remove these outliers reliably and without supervision.]]></description>
</item></channel>
</rss>
