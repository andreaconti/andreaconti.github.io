<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>wacv - Tag - Andrea Conti PhD</title>
        <link>https://andreaconti.github.io/tags/wacv/</link>
        <description>wacv - Tag - Andrea Conti PhD</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>andrea.conti@tutanota.com (Andrea Conti)</managingEditor>
            <webMaster>andrea.conti@tutanota.com (Andrea Conti)</webMaster><lastBuildDate>Sun, 07 Jul 2024 17:32:00 &#43;0200</lastBuildDate><atom:link href="https://andreaconti.github.io/tags/wacv/" rel="self" type="application/rss+xml" /><item>
    <title>Depth on Demand: Streaming Dense Depth from a Low Frame Rate Active Sensor</title>
    <link>https://andreaconti.github.io/projects/depth_on_demand/</link>
    <pubDate>Sun, 07 Jul 2024 17:32:00 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://andreaconti.github.io/projects/depth_on_demand/</guid>
    <description><![CDATA[Andrea Conti &middot Matteo Poggi &middot Valerio Cambareri &middot Stefano Mattoccia [Paper] [Code] Overview In the last decade, RGB-D camera systems have become prominent in robotics, automotive and augmented reality. Moreover, they are now available on mobile handheld devices, usually coupled with RGB cameras. However, such sensors either do not provide high frame rate, high resulution or suffer heating and high energy consumption, particularly meaningful in the mobile use case.]]></description>
</item><item>
    <title>Sparsity Agnostic Depth Completion</title>
    <link>https://andreaconti.github.io/projects/sparsity_agnostic_depth_completion/</link>
    <pubDate>Tue, 03 Jan 2023 17:32:00 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://andreaconti.github.io/projects/sparsity_agnostic_depth_completion/</guid>
    <description><![CDATA[Andrea Conti &middot Matteo Poggi &middot Stefano Mattoccia [Paper] [Code] Overview State-of-the-art Depth Completion approaches yield accurate results only when processing a specific density and distribution of input points, i.e. the one observed during training, narrowing their deployment in real use cases. We present a framework:
robust to uneven distributions and extremely low densities by structure trained with a fixed pattern and density as competitors, without any need of augmenting Experimental results on standard indoor and outdoor benchmarks highlight the robustness of our framework, achieving accuracy comparable to state-of-the-art methods when tested with density and distribution equal to the training one while being much more accurate in the other cases.]]></description>
</item></channel>
</rss>
